<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuralNetworkCpp: /home/brabo/Projetos/neural-network-cpp/src/LossFunctions.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NeuralNetworkCpp
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
   <div id="projectbrief">A library for neural network implementation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">LossFunctions.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_loss_functions_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef LOSS_FUNCTIONS_H</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define LOSS_FUNCTIONS_H</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160; </div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160; </div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="_layer_8h.html">Layer.h</a>&quot;</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="_network_8h.html">Network.h</a>&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160; </div>
<div class="line"><a name="l00010"></a><span class="lineno"><a class="line" href="namespace_loss_functions.html">   10</a></span>&#160;<span class="keyword">namespace </span><a class="code" href="namespace_loss_functions.html">LossFunctions</a> {</div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160; </div>
<div class="line"><a name="l00020"></a><span class="lineno"><a class="line" href="namespace_loss_functions.html#a426ed624070c659aa68f8b73e3c2e9d5">   20</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">double</span> <a class="code" href="namespace_loss_functions.html#a426ed624070c659aa68f8b73e3c2e9d5">meanSquaredErrorLoss</a>(<span class="keyword">const</span> std::vector&lt;double&gt;&amp; expectedOutputs,</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;                                   <span class="keyword">const</span> std::vector&lt;double&gt;&amp; forwardOutput) {</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;    <span class="keywordtype">double</span> loss = 0.0;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160; </div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;    <span class="comment">// Calculate error</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;    <span class="keywordtype">double</span> sampleLoss = 0.0;</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; expectedOutputs.size(); j++) {</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;        <span class="keywordtype">double</span> diff = expectedOutputs[j] - forwardOutput[j];</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;        sampleLoss += diff * diff;</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;    }</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;    sampleLoss /= expectedOutputs.size();</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160; </div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    loss += sampleLoss;</div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160; </div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;    <span class="keywordflow">return</span> loss;</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;}</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160; </div>
<div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="namespace_loss_functions.html#a2213a3103ee924258055014039a80f99">   44</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">double</span> <a class="code" href="namespace_loss_functions.html#a2213a3103ee924258055014039a80f99">crossEntropyLoss</a>(<span class="keyword">const</span> std::vector&lt;double&gt;&amp; expectedOutputs,</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;                               <span class="keyword">const</span> std::vector&lt;double&gt;&amp; forwardOutput) {</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;    <span class="comment">// Calculate cross-entropy loss</span></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    <span class="keywordtype">double</span> loss = 0.0;</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; expectedOutputs.size(); j++) {</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;        <span class="keywordtype">double</span> output = forwardOutput[j];</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;        <span class="keywordflow">if</span> (output &lt; std::numeric_limits&lt;double&gt;::epsilon()) {</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;            output = std::numeric_limits&lt;double&gt;::epsilon();</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (output &gt; 1.0 - std::numeric_limits&lt;double&gt;::epsilon()) {</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;            output = 1.0 - std::numeric_limits&lt;double&gt;::epsilon();</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        }</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;        loss -= expectedOutputs[j] * std::log(output);</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    }</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    <span class="keywordflow">return</span> loss;</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;}</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160; </div>
<div class="line"><a name="l00068"></a><span class="lineno"><a class="line" href="namespace_loss_functions.html#a8da915309c176064d2a871a04e4d1dd5">   68</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">double</span> <a class="code" href="namespace_loss_functions.html#a8da915309c176064d2a871a04e4d1dd5">binaryCrossEntropyLoss</a>(<span class="keyword">const</span> std::vector&lt;double&gt;&amp; expectedOutputs,</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;                                     <span class="keyword">const</span> std::vector&lt;double&gt;&amp; forwardOutput) {</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="comment">// Calculate binary cross-entropy loss</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keywordtype">double</span> loss = 0.0;</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; expectedOutputs.size(); j++) {</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;        <span class="keywordtype">double</span> output = forwardOutput[j];</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        <span class="keywordflow">if</span> (output &lt; std::numeric_limits&lt;double&gt;::epsilon()) {</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;            output = std::numeric_limits&lt;double&gt;::epsilon();</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (output &gt; 1.0 - std::numeric_limits&lt;double&gt;::epsilon()) {</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;            output = 1.0 - std::numeric_limits&lt;double&gt;::epsilon();</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        }</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        loss -= expectedOutputs[j] * std::log(output) +</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;                (1.0 - expectedOutputs[j]) * std::log(1.0 - output);</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    }</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keywordflow">return</span> loss;</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;}</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160; </div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;}  <span class="comment">// namespace LossFunctions</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160; </div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="preprocessor">#endif  </span><span class="comment">// LOSS_FUNCTIONS_H</span></div>
<div class="ttc" id="a_layer_8h_html"><div class="ttname"><a href="_layer_8h.html">Layer.h</a></div></div>
<div class="ttc" id="a_network_8h_html"><div class="ttname"><a href="_network_8h.html">Network.h</a></div></div>
<div class="ttc" id="anamespace_loss_functions_html"><div class="ttname"><a href="namespace_loss_functions.html">LossFunctions</a></div><div class="ttdef"><b>Definition:</b> LossFunctions.h:10</div></div>
<div class="ttc" id="anamespace_loss_functions_html_a2213a3103ee924258055014039a80f99"><div class="ttname"><a href="namespace_loss_functions.html#a2213a3103ee924258055014039a80f99">LossFunctions::crossEntropyLoss</a></div><div class="ttdeci">static double crossEntropyLoss(const std::vector&lt; double &gt; &amp;expectedOutputs, const std::vector&lt; double &gt; &amp;forwardOutput)</div><div class="ttdoc">Calculates the cross-entropy loss between the expected outputs and the forward output.</div><div class="ttdef"><b>Definition:</b> LossFunctions.h:44</div></div>
<div class="ttc" id="anamespace_loss_functions_html_a426ed624070c659aa68f8b73e3c2e9d5"><div class="ttname"><a href="namespace_loss_functions.html#a426ed624070c659aa68f8b73e3c2e9d5">LossFunctions::meanSquaredErrorLoss</a></div><div class="ttdeci">static double meanSquaredErrorLoss(const std::vector&lt; double &gt; &amp;expectedOutputs, const std::vector&lt; double &gt; &amp;forwardOutput)</div><div class="ttdoc">Calculates the mean squared error loss between the expected outputs and the forward output.</div><div class="ttdef"><b>Definition:</b> LossFunctions.h:20</div></div>
<div class="ttc" id="anamespace_loss_functions_html_a8da915309c176064d2a871a04e4d1dd5"><div class="ttname"><a href="namespace_loss_functions.html#a8da915309c176064d2a871a04e4d1dd5">LossFunctions::binaryCrossEntropyLoss</a></div><div class="ttdeci">static double binaryCrossEntropyLoss(const std::vector&lt; double &gt; &amp;expectedOutputs, const std::vector&lt; double &gt; &amp;forwardOutput)</div><div class="ttdoc">Calculates the binary cross-entropy loss between the expected outputs and the forward output.</div><div class="ttdef"><b>Definition:</b> LossFunctions.h:68</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Jun 1 2023 21:58:56 for NeuralNetworkCpp by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
